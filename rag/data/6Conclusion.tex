
\section{Conclusion}

% In this paper, we introduced \textit{DSLR} (Document Sentence-Level re-ranking and Reconstruction), an unsupervised method designed to enhance the precision and relevance of RAG systems. Our approach addresses key challenges in current RAG frameworks, particularly the issues of redundancy and irrelevance in retrieved passages. By decomposing passages into sentences, re-ranking them based on query relevance, and reconstructing the sentences to passages to maintain contextual integrity, \textit{DSLR} improves both accuracy and coherence of the generated responses.

% Through extensive experiments on multiple open-domain QA datasets, including both general and specialized domains, our method consistently outperformed traditional passage-level re-ranking approaches. The results demonstrated significant improvements in answer accuracy, particularly in dynamic and domain-specific contexts, affirming the robustness and adaptability of \textit{DSLR}. Furthermore, our ablation studies underscored the critical importance of sentence-level re-ranking and contextual reconstruction in enhancing RAG performance.

% In conclusion, \textit{DSLR} offers a promising solution for refining retrieved documents without additional training, paving the way for more effective and efficient RAG systems in various knowledge-intensive NLP tasks. Future work may explore integrating \textit{DSLR} with other retrieval and ranking models to further enhance its capabilities.
In this work, we present \textit{DSLR}, a novel unsupervised document refinement framework that enhances the performance of RAG systems. The \textit{DSLR} framework aids RAG systems to generate more accurate answers by decomposing passages into sentences, re-ranking them based on each relevance score, and then reconstructing them to preserve the continuity and coherence of the context. Our comprehensive experiments on multiple QA datasets show that \textit{DSLR} consistently outperforms the conventional approaches of using fixed-size passage in RAG, especially in ever-evolving and domain-specific contexts. Our ablation studies highlight the importance of sentence-level re-ranking and contextual reconstruction for improvement on RAG. We believe that \textit{DSLR} suggests a promising research direction for refining document retrieval without additional training, together with potential applications across a wide range of knowledge-intensive NLP tasks by integrating more diverse retrieval or ranking models. %Future work may explore \textit{DSLR}'s integration with other retrieval and ranking models to enhance its effectiveness.